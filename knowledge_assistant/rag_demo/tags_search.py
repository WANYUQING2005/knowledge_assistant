# -*- coding: utf-8 -*-
"""
tag_search.py
åŸºäºâ€œæ ‡ç­¾â€çš„æ™ºèƒ½æœç´¢ï¼ˆå…¼å®¹å¤š OpenAI é£æ ¼æ¥å£ï¼‰ï¼š
ç°åœ¨æ•°æ®åº“é‡Œ title å°±æ˜¯æ ‡ç­¾ã€‚
"""

import os
import json
from typing import List, Dict, Any, Set
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from sqlalchemy.engine import URL
from langchain_openai import ChatOpenAI

load_dotenv()


# ------------------ LLM ------------------

def _build_llm():
    return ChatOpenAI(
        api_key=os.getenv("API_KEY"),
        base_url=os.getenv("API_BASE", "https://api.deepseek.com"),
        model=os.getenv("MODEL", "deepseek-chat"),
        temperature=0.1,
    )


# ------------------ DB ------------------

def _build_engine():
    url_env = os.getenv("MYSQL_URL")
    if url_env:
        return create_engine(url_env, pool_pre_ping=True)

    url_obj = URL.create(
        "mysql+pymysql",
        username=os.getenv("MYSQL_USER", "root"),
        password=os.getenv("MYSQL_PASSWORD", "yourpassword"),
        host=os.getenv("MYSQL_HOST", "localhost"),
        port=int(os.getenv("MYSQL_PORT", "3306")),
        database=os.getenv("MYSQL_DB", "knowledge_assistant"),
    )
    return create_engine(url_obj, pool_pre_ping=True)


# ------------------ æ ¸å¿ƒç±» ------------------

class TagBasedSearch:
    """åŸºäºæ ‡ç­¾çš„æœç´¢ï¼šæ”¶é›†æ ‡ç­¾ â†’ LLM åŒ¹é… â†’ å–å›ç›¸å…³ chunks"""

    def __init__(self):
        self.engine = _build_engine()
        self.llm = _build_llm()

    # âœ… ç°åœ¨ç›´æ¥ç”¨ title å­—æ®µä½œä¸ºæ ‡ç­¾
    def get_all_tags(self) -> Set[str]:
        tags: Set[str] = set()
        sql = text("SELECT DISTINCT title FROM knowledge_ragchunks WHERE title IS NOT NULL AND title != ''")
        with self.engine.begin() as conn:
            for row in conn.execute(sql):
                if row.title and row.title.strip():
                    tags.add(row.title.strip())
        return tags

    def _llm_match(self, query: str, all_tags: Set[str], topk: int = 10) -> List[str]:
        """ç”¨ LLM ä»æ ‡ç­¾é›†ä¸­ç­›é€‰æœ€ç›¸å…³æ ‡ç­¾ï¼›å¤±è´¥å›é€€åˆ°å­—ç¬¦ä¸²åŒ¹é…"""
        if not all_tags:
            return []

        tags_str = "\n".join(f"- {t}" for t in sorted(all_tags))
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªç²¾ç¡®çš„æ ‡ç­¾åŒ¹é…ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„æœç´¢æŸ¥è¯¢ï¼Œä»ç»™å®šçš„æ ‡ç­¾åˆ—è¡¨ä¸­ä¸¥æ ¼ç­›é€‰æœ€ç›¸å…³çš„æ ‡ç­¾ã€‚

ç”¨æˆ·æœç´¢æŸ¥è¯¢: "{query}"

å¯ç”¨æ ‡ç­¾åˆ—è¡¨:
{tags_str}

è¯·ä¸¥æ ¼éµå¾ªï¼š
1) ä»…é€‰æ‹©ä¸æŸ¥è¯¢é«˜åº¦ç›¸å…³çš„æ ‡ç­¾ï¼ˆå®ç¼ºæ¯‹æ»¥ï¼‰
2) åŒä¹‰è¯/ä¸“ä¸šç­‰ä»·è¡¨è¾¾å¯è§†ä¸ºç›¸å…³
3) æŒ‰ç›¸å…³åº¦ä»é«˜åˆ°ä½æ’åº
4) è¾“å‡ºæ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªæ ‡ç­¾ï¼Œä¸è¦é¢å¤–è¯´æ˜
"""

        try:
            resp = self.llm.invoke([{"role": "user", "content": prompt}])
            text_out = resp.content if hasattr(resp, "content") else (resp or "")
            matched: List[str] = []
            for line in text_out.strip().splitlines():
                tag = line.strip().lstrip("-").strip()
                if tag and (tag in all_tags) and (tag not in matched):
                    matched.append(tag)
            return matched[:topk] if matched else self._fallback_match(query, all_tags, topk)
        except Exception as e:
            print(f"[WARN] LLM åŒ¹é…å¤±è´¥ï¼Œå›é€€åˆ°å­—ç¬¦ä¸²åŒ¹é…: {e}")
            return self._fallback_match(query, all_tags, topk)

    def _fallback_match(self, query: str, all_tags: Set[str], topk: int = 10) -> List[str]:
        q = query.lower().strip()
        hits = [t for t in all_tags if q in t.lower() or t.lower() in q]
        seen, result = set(), []
        for t in hits:
            if t not in seen:
                seen.add(t)
                result.append(t)
            if len(result) >= topk:
                break
        return result

    # âœ… æ ¹æ® title å– chunks
    def get_chunks_by_tags(self, tags: List[str], limit_per_tag: int = 50) -> List[Dict[str, Any]]:
        if not tags:
            return []

        conds, params = [], {}
        for i, t in enumerate(tags):
            pn = f"tag_{i}"
            conds.append(f"title = :{pn}")
            params[pn] = t
        where_clause = " OR ".join(conds)

        sql = text(f"""
            SELECT
                id, title, content, vector_id, number, word_count,
                document_id, creater_id, create_at, `kb id`
            FROM knowledge_ragchunks
            WHERE {where_clause}
            ORDER BY document_id ASC, number ASC
            LIMIT :lim
        """)
        params["lim"] = limit_per_tag * max(1, len(tags))

        out: List[Dict[str, Any]] = []
        with self.engine.begin() as conn:
            for row in conn.execute(sql, params):
                out.append({
                    "id": row.id,
                    "title": row.title,
                    "content": row.content,
                    "vector_id": row.vector_id,
                    "number": row.number,
                    "word_count": row.word_count,
                    "document_id": row.document_id,
                    "creater_id": row.creater_id,
                    "create_at": str(row.create_at),
                    "kb_id": getattr(row, "kb id", None)
                })
        return out

    def search_by_tags(self, query: str, topk_tags: int = 8, limit_per_tag: int = 50) -> Dict[str, Any]:
        print(f"ğŸ” åŸºäºæ ‡ç­¾æœç´¢ï¼š{query}")
        all_tags = self.get_all_tags()
        print(f"[INFO] æ ‡ç­¾æ€»æ•°ï¼š{len(all_tags)}")
        if not all_tags:
            return {"query": query, "matched_tags": [], "chunks": [], "message": "æ•°æ®åº“ä¸­æ²¡æœ‰ä»»ä½•æ ‡ç­¾"}

        matched = self._llm_match(query, all_tags, topk=topk_tags)
        print(f"[INFO] åŒ¹é…æ ‡ç­¾ï¼š{matched}")
        if not matched:
            return {"query": query, "matched_tags": [], "chunks": [], "message": "æœªåŒ¹é…åˆ°ç›¸å…³æ ‡ç­¾"}

        chunks = self.get_chunks_by_tags(matched, limit_per_tag=limit_per_tag)
        print(f"[INFO] å‘½ä¸­çŸ¥è¯†å—ï¼š{len(chunks)}")
        return {
            "query": query,
            "matched_tags": matched,
            "chunks": chunks,
            "message": f"å‘½ä¸­ {len(chunks)} ä¸ªçŸ¥è¯†å—"
        }


# ------------------ CLI ------------------

def main():
    searcher = TagBasedSearch()
    print("=" * 60)
    print("ğŸ·ï¸  åŸºäºæ ‡ç­¾çš„æ™ºèƒ½æœç´¢ï¼ˆå…¼å®¹å¤š OpenAI æ¥å£ï¼‰")
    print("=" * 60)
    print("è¾“å…¥æœç´¢è¯å¹¶å›è½¦ï¼›è¾“å…¥ exit é€€å‡ºã€‚\n")

    while True:
        try:
            q = input("ğŸ” è¯·è¾“å…¥æœç´¢è¯: ").strip()
            if not q:
                continue
            if q.lower() == "exit":
                print("ğŸ‘‹ å†è§ï¼")
                break

            result = searcher.search_by_tags(q)

            print("\n" + "=" * 50)
            print("ğŸ¯ æœç´¢ç»“æœ")
            print("=" * 50)

            # æ ‡ç­¾
            tags = result.get("matched_tags") or []
            print("ğŸ“Œ åŒ¹é…çš„æ ‡ç­¾ï¼š", ", ".join(tags) if tags else "æ— ")

            # çŸ¥è¯†å—
            chs = result.get("chunks") or []
            if chs:
                print(f"\nğŸ“š ç›¸å…³çŸ¥è¯†å—ï¼ˆå±•ç¤ºå‰ 5 æ¡ï¼Œå…± {len(chs)} æ¡ï¼‰\n")
                for i, ch in enumerate(chs[:5], 1):
                    preview = (ch["content"][:200] + "...") if len(ch["content"]) > 200 else ch["content"]
                    print(f"--- çŸ¥è¯†å— {i} ---")
                    print(f"ğŸ“„ æ–‡æ¡£: {ch['title']}")
                    print(f"ğŸ›£  æº: {ch.get('source', '-')}")
                    print(f"ğŸ§­ å‘é‡ID: {ch.get('vector_id')}")
                    print(f"ğŸ“ å†…å®¹: {preview}\n")
                if len(chs) > 5:
                    print(f"... è¿˜æœ‰ {len(chs) - 5} æ¡")
            else:
                print("âŒ æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†å—")

            print("ğŸ’¡", result.get("message", ""))

            print("\n" + "=" * 50 + "\n")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‡ºé”™ï¼š{e}")


if __name__ == "__main__":
    main()
